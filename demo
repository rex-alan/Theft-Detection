#LAB 1 (basic image operations)

#colors
import cv2  
image = cv2.imread('sample.jpeg')
B, G, R = cv2.split(image)
# Corresponding channels are seperated
cv2.imshow("original", image)
cv2.imshow("blue", B)
cv2.imshow("Green", G)
cv2.imshow("red", R)
cv2.waitKey(0)
cv2.destroyAllWindows()

#pixels
import cv2
from PIL import Image
input_image = Image.open('sample.jpeg')
pixel_map = input_image.load()
width, height = input_image.size
for i in range(width//2):
    for j in range(height):
        r, g, b = input_image.getpixel((i, j))
        grayscale = (0.299*r + 0.587*g + 0.114*b)
        pixel_map[i, j] = (int(grayscale), int(grayscale), int(grayscale))
input_image.save("grayscale", format="png")
input_image.show()

#filter
from PIL import Image, ImageFilter
im1 = Image.open('sample.jpeg')
im2 = im1.filter(ImageFilter.CONTOUR)
im2.show()

#blur
import cv2
img = cv2.imread('sample.jpeg')
blurImg = cv2.blur(img,(10,10))
cv2.imshow('blurred image',blurImg)
cv2.waitKey(0)
cv2.destroyAllWindows()

#erosion and dilation
import cv2
import numpy as np
img = cv2.imread('download.png', 0)
kernel = np.ones((5,5), np.uint8)
img_erosion = cv2.erode(img, kernel, iterations=1)
img_dilation = cv2.dilate(img, kernel, iterations=1)
cv2.imshow('Input', img)
cv2.imshow('Erosion', img_erosion)
cv2.imshow('Dilation', img_dilation)
cv2.waitKey(0)


#LAB 2 ( To perform scaling ,rotating and transforming images.)
#scaling
import cv2
import numpy as np
FILE_NAME = 'images/ring.jpg'
try:
    img = cv2.imread(FILE_NAME)
    (height, width) = img.shape[:2]
    print(height,width)
    res = cv2.resize(img, (int(width / 2), int(height / 2)), interpolation = cv2.INTER_CUBIC)
    cv2.imshow('Orginal',img)
    cv2.imshow('Scale image',res)
    cv2.waitKey(0)
except IOError:
        print ('Error while reading files !!!')

import cv2
import numpy as np
FILE_NAME = 'images/ring.jpg'
try:
    img = cv2.imread(FILE_NAME)
    (height, width) = img.shape[:2]
    print(height,width)
    dim=height*2, width *2
    res = cv2.resize(img,dim)
    cv2.imshow('Orginal',img)
    cv2.imshow('Scale image',res)
    cv2.waitKey(0)
    #cv2.imwrite('result.jpg', res)
except IOError:
        print ('Error while reading files !!!')
        
# rotating
import cv2   
img = cv2.imread('images/ring.jpg')  
(h, w) = img.shape[:2]  
center = (w / 2, h / 2)  
print(center)
angle90 = 90  
angle180 = 180  
angle270 = 270  
scale = 1.0   
M = cv2.getRotationMatrix2D(center, angle90, scale)  
rotated90 = cv2.warpAffine(img, M, (h, w))  
  
# 180 degrees  
M = cv2.getRotationMatrix2D(center, angle180, scale)  
rotated180 = cv2.warpAffine(img, M, (w, h))  
  
# 270 degrees  
M = cv2.getRotationMatrix2D(center, angle270, scale)  
rotated270 = cv2.warpAffine(img, M, (h, w))  
  
cv2.imshow('Original Image', img)  
#cv2.waitKey(0)  # waits until a key is pressed  
#cv2.destroyAllWindows()  # destroys the window showing image  
  
cv2.imshow('Image rotated by 90 degrees', rotated90)  
#cv2.waitKey(0)  # waits until a key is pressed  
#cv2.destroyAllWindows()  # destroys the window showing imag  
  
cv2.imshow('Image rotated by 180 degrees', rotated180)  
#cv2.waitKey(0)  # waits until a key is pressed  
#cv2.destroyAllWindows()  # destroys the window showing image  
  
cv2.imshow('Image rotated by 270 degrees', rotated270)  
cv2.waitKey(0)  # waits until a key is pressed  
cv2.destroyAllWindows()  # destroys the window showing image

#transformation
import cv2
import numpy as np
  
image = cv2.imread('images/ring.jpg')
  
# Store height and width of the image
height, width = image.shape[:2]
  
quarter_height, quarter_width = height / 4, width / 4
  
T = np.float32([[1, 0, quarter_width], [0, 1, quarter_height]])
print(T)
  
# We use warpAffine to transform
# the image using the matrix, T
img_translation = cv2.warpAffine(image, T, (width, height))
  
cv2.imshow("Originalimage", image)
cv2.imshow('Translation', img_translation)
cv2.waitKey()
  
cv2.destroyAllWindows()


LAB 3 (skew detection and correction using image processing.)

import cv2 
import numpy as np 
img=cv2.imread("skew.png") 
gray_img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) 
gray_img=cv2.bitwise_not(gray_img) 
coordinates=np.column_stack(np.where(gray_img>0)) 
ang=cv2.minAreaRect(coordinates)[-1] if ang<-45:     ang=-(90+ang) else:     ang=-ang     height,width=img.shape[:2] 
centre=(width/2,height/2) 
rotationMatrix=cv2.getRotationMatrix2D(centre,ang,1.0) 
rotated_img=cv2.warpAffine(img,rotationMatrix, (width,height),flags=cv2.INTER_CUBIC,borderMode=cv2.BORDER_REFLECT) 
cv2.imshow("Roated Image",rotated_img) 
cv2.waitKey(0) 


LAB - 4 (IMAGE PROCESSING WITH THRESHLDING)

import cv2
import numpy as np
image1 = cv2.imread('lshorse.jpg')
img = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)
ret, thresh1 = cv2.threshold(img, 120, 255, cv2.THRESH_BINARY)
print(ret, thresh1)
ret, thresh2 = cv2.threshold(img, 120, 255, cv2.THRESH_BINARY_INV)
ret, thresh3 = cv2.threshold(img, 120, 255, cv2.THRESH_TRUNC)
ret, thresh4 = cv2.threshold(img, 120, 255, cv2.THRESH_TOZERO)
ret, thresh5 = cv2.threshold(img, 120, 255, cv2.THRESH_TOZERO_INV)
cv2.imshow('Orginal Image', image1)
cv2.imshow('Binary Threshold', thresh1)
cv2.imshow('Binary Threshold Inverted', thresh2)
cv2.imshow('Truncated Threshold', thresh3)
cv2.imshow('Set to 0', thresh4)
cv2.imshow('Set to 0 Inverted', thresh5)
cv2.waitKey(0)
cv2.destroyAllWindows()


LAB - 5 (contour object detection and edge detection.)

#Program for Contour Object Detection and Edge Detection

import cv2
img = cv2.imread('images/ring.jpg')
edges = cv2.Canny(img,200,300,True)  # detection of the edges
cv2.imshow("Edge Detected Image", edges) 
cv2.imshow("Original Image", img)
cv2.waitKey(0)
cv2.destroyAllWindows()  

import cv2
from matplotlib import pyplot as plt
image = cv2.imread('images/house.jpg')
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
_, binary = cv2.threshold(gray, 225, 255, cv2.THRESH_BINARY_INV)
contours, hierarchy = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
image = cv2.drawContours(image, contours, -1, (255, 0, 0), 4)
plt.subplot(121),plt.imshow(binary, cmap="gray")
plt.subplot(122),plt.imshow(image)
plt.show()


LAB - 6 (GET TEXT FROM IMAGE USING PYTHON) (DIGIT DETECTION)

from PIL import Image, ImageEnhance, ImageFilter
import pytesseract
import os
path = 'images/text.gif'
img = Image.open(path)
img = img.convert('RGBA')
pix = img.load()
#print(pix[x, y])
for y in range(img.size[1]):
    for x in range(img.size[0]):
        if pix[x, y][0] < 102 or pix[x, y][1] < 102 or pix[x, y][2] < 102:
            pix[x, y] = (0, 0, 0, 255)
        else:
            pix[x, y] = (255, 255, 255, 255)
img.save('temp.png')
img.show()
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'
text = pytesseract.image_to_string(Image.open('temp.png'))
print(text)


LAB - 7 (HANDLING VIDEO INPUT)


import numpy as np
import cv2

cap = cv2.VideoCapture(0)
fourcc = cv2.VideoWriter_fourcc(*'XVID')
out = cv2.VideoWriter('frame.avi',fourcc, 20.0, (640,480))

while(True):
    ret, frame = cap.read()
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    out.write(frame)
    cv2.imshow('frame',gray)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
out.release()
cv2.destroyAllWindows()


LAB - 8 (MOTION DETECTION USING OPENCV )


import cv2, time, pandas
# importing datetime class from datetime library
from datetime import datetime
 
# Assigning our static_back to None
static_back = None
 
# List when any moving object appear
motion_list = [ None, None ]
 
# Time of movement
time = []
 
# Initializing DataFrame, one column is start
# time and other column is end time
df = pandas.DataFrame(columns = ["Start", "End"])
 
# Capturing video
video = cv2.VideoCapture(0) #0 is the default camera (webcam) of my computer
 
# Infinite while loop to treat stack of images as video
while True:
    # Reading frame(image) from video
    check, frame = video.read()
 
    # Initializing motion = 0(no motion)
    motion = 0
 
    # Converting color image to gray_scale image
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
 
    # Converting gray scale image to GaussianBlur
    # so that change can be found easily and  for better accuracy
    gray = cv2.GaussianBlur(gray, (21, 21), 0)
 
    # In first iteration we assign the value
    # of static_back to our first frame
    if static_back is None:
        static_back = gray 
        continue # skip the rest of the lines in this iteration

 
    # Difference between static background (first frame)
    # and current frame (which is GaussianBlur)
    diff_frame = cv2.absdiff(static_back, gray)
 
    # If change in between static background and
    # current frame is greater than 30 it will show white color(255)
    thresh_frame = cv2.threshold(diff_frame, 30, 255, cv2.THRESH_BINARY)[1]
    thresh_frame = cv2.dilate(thresh_frame, None, iterations = 2)
 
    # Finding contour of moving object   i.e. find all contours in the thres_frame
    cnts,_ = cv2.findContours(thresh_frame.copy(),
                       cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
  # filter the contours that have more than 10000 pixels
    for contour in cnts:
        if cv2.contourArea(contour) < 10000:
            continue
        motion = 1 #first object found entering the frame
  # draw a rectangle around the contour
        (x, y, w, h) = cv2.boundingRect(contour)
        # making green rectangle around the moving object
        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 3)
 
    # Appending status of motion
    motion_list.append(motion)
  #we only need to retain the last two items in the list
    motion_list = motion_list[-2:]
 
    # Appending Start time of motion
    if motion_list[-1] == 1 and motion_list[-2] == 0:
        time.append(datetime.now())
 
    # Appending End time of motion
    if motion_list[-1] == 0 and motion_list[-2] == 1:
        time.append(datetime.now())
 
    # Displaying image in gray_scale
    cv2.imshow("Gray Frame", gray)
 
    # Displaying the difference in currentframe to
    # the staticframe(very first_frame)
    cv2.imshow("Difference Frame", diff_frame)
 
    # Displaying the black and white image in which if
    # intensity difference greater than 30 it will appear white
    cv2.imshow("Threshold Frame", thresh_frame)
 
    # Displaying color frame with contour of motion of object
    cv2.imshow("Color Frame", frame)
 
    key = cv2.waitKey(1)
    # if q entered whole process will stop
    if key == ord('q'):
        # if something is moving then it appends the end time of movement
        if motion == 1:
            time.append(datetime.now())
        break
     #end of loop

# Appending time of motion in DataFrame
for i in range(0, len(time), 2):
    df = df.append({"Start":time[i], "End":time[i + 1]}, ignore_index = True)
 
#If you set this parameter to ignore_index = True , Pandas will ignore the index values in the inputs, and will generate a new index for the output.
# Creating a CSV file in which time of movements will be saved
df.to_csv("Time_of_movements.csv")
 
video.release()
 
# Destroying all the windows
cv2.destroyAllWindows()


LAB - 9 (CAR NUMBER PLATE)


import cv2
import imutils
import numpy as np
import pytesseract
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

img = cv2.imread('images/car.jpg',cv2.IMREAD_COLOR)
img = cv2.resize(img, (600,400) )

gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) 
gray = cv2.bilateralFilter(gray, 13, 15, 15) 

edged = cv2.Canny(gray, 30, 200) 

# find contours in the image
contours = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
contours = imutils.grab_contours(contours)
contours = sorted(contours, key = cv2.contourArea, reverse = True)[:10]
screenCnt = None

  
# loop over the contours
for c in contours:
    # approximate the contour
    peri = cv2.arcLength(c, True)
    approx = cv2.approxPolyDP(c, 0.018 * peri, True)
 # if the approximated contour has 4 vertices, then we are examining
    # a rectangle
    if len(approx) == 4:
        screenCnt = approx
        break

if screenCnt is None:
    detected = 0
    print ("No contour detected")
else:
     detected = 1

if detected == 1:
    # draw the outline of the contour and draw the text on the image
    cv2.drawContours(img, [screenCnt], -1, (0, 0, 255), 3)

mask = np.zeros(gray.shape,np.uint8)
new_image = cv2.drawContours(mask,[screenCnt],0,255,-1,)
new_image = cv2.bitwise_and(img,img,mask=mask)

(x, y) = np.where(mask == 255)
(topx, topy) = (np.min(x), np.min(y))
(bottomx, bottomy) = (np.max(x), np.max(y))
Cropped = gray[topx:bottomx+1, topy:bottomy+1]

text = pytesseract.image_to_string(Cropped, config='--psm 11')
print("License Plate Recognition\n")
print("Detected license plate Number is:",text)
img = cv2.resize(img,(500,300))
Cropped = cv2.resize(Cropped,(400,200))
cv2.imshow('car',img)
cv2.imshow('Cropped',Cropped)

cv2.waitKey(0)
cv2.destroyAllWindows()
